## Research Notes

This repository represents ongoing independent research exploration.

Detailed methodology: [docs/methodology.md](docs/methodology.md)

Medium article Link - https://medium.com/@ddbrao11/learning-rna-structure-from-sequence-with-transformer-based-models-a-research-exploration-5769e4f826ab?postPublishedType=repub


## Research Motivation

RNA structure prediction remains a major challenge in computational biology,
with implications for drug discovery and biological engineering.
This repository explores transformer-based approaches for learning
sequence-to-structure representations using publicly available benchmark datasets.

## Research Questions

- Can transformer architectures capture structural dependencies?
- How well can sequence-only models predict 3D structure?
- What limitations arise without geometric inductive bias?

## Approach
Sequence tokenization, transformer-based modeling,
and coordinate prediction workflows evaluated
using publicly available benchmark datasets.

## Limitations
Transformers lack explicit geometric constraints.
Future work may explore equivariant neural networks
or hybrid modeling approaches.

## Methodology Overview
RNA Sequence → Tokenizer → Transformer Encoder → Regression Head → 3D Coordinates

## Experimental Design

- Dataset: public benchmark RNA folding dataset
- Baselines: lightweight regressors / simple neural baseline
- Evaluation: structural similarity metrics + error analysis

### Experimental Workflow (Conceptual Overview)
```
+-------------------------+
| RNA Sequence Dataset    |
+-----------+-------------+
            |
            v
+-------------------------+
| Data Preparation        |
| Tokenization & Encoding |
+-----------+-------------+
            |
            v
+-------------------------+
| Baseline Model          |
+-----------+-------------+
            |
            v
+-------------------------+
| Transformer Model       |
| (Self-Attention)        |
+-----------+-------------+
            |
            v
+-------------------------+
| Training & Validation   |
+-----------+-------------+
            |
            v
+-------------------------+
| Structural Prediction   |
+-----------+-------------+
            |
            v
+-------------------------+
| Evaluation & Analysis   |
+-------------------------+
```


## Observations

Early experiments suggest the model captures long-range relationships,
though geometric constraints remain challenging.

## Future Research

- SE(3)-equivariant networks
- Graph neural networks for structural modeling
- Multi-task learning approaches

## Reproducibility
- Python: 3.x





